{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09892202",
   "metadata": {},
   "source": [
    "# Sentiment polarity\n",
    "Techniques like TF-IDF and word embeddings help capture semantic relationships and represent text numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a74d5a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "os.chdir(\"C:/Sereda/Job/portfolio/Python/Sentiment\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string # string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "17b03bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victoria\\AppData\\Local\\Temp\\ipykernel_15472\\991684456.py:2: DtypeWarning: Columns (1,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reviews = pd.read_csv('customer_reviews.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load customer review data\n",
    "reviews = pd.read_csv('customer_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "95f535ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34660, 2)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = reviews.loc[:,['reviews.text','reviews.doRecommend']] # Review text and sentiment\n",
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "78b55c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.doRecommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This product so far has not disappointed. My c...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great for beginner or experienced person. Boug...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews.text reviews.doRecommend\n",
       "0  This product so far has not disappointed. My c...                True\n",
       "1  great for beginner or experienced person. Boug...                True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9ec1c2",
   "metadata": {},
   "source": [
    "This is a list of over 34,000 consumer reviews for Amazon products like the Kindle, Fire TV Stick, and more provided by Datafiniti's Product Database. The dataset includes basic product information, rating, review text, and more for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fd91cded",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviews.text             1\n",
       "reviews.doRecommend    594\n",
       "dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "28911e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34066, 2)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = reviews.loc[~pd.isnull(reviews['reviews.doRecommend'])] # remove NaN\n",
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "91c249ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviews.text           0\n",
       "reviews.doRecommend    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1e73ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['reviews.doRecommend'] = reviews['reviews.doRecommend'].astype('int') # {True, False} -> {1, 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d820762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c94ca3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Data Preprocessing**\n",
    "def preprocess_text(text):\n",
    "    if(type(text) == str):\n",
    "        # Remove punctuation and special characters\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Tokenize the text\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        # Remove stop words\n",
    "        sw = nltk.corpus.stopwords.words('english') # stop words\n",
    "        for w in ['no','not']: sw.remove(w) # remove 'no' and 'not' from the list of stop words\n",
    "        tokens = [token for token in tokens if token not in sw]\n",
    "        # Stem the tokens\n",
    "        stemmer = nltk.PorterStemmer()\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "        # Join the tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    else:\n",
    "        return(\"absent\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b51ad3e",
   "metadata": {},
   "source": [
    "txt = reviews.loc[0, 'reviews.text'] # first review text to see how this function works\n",
    "recom = reviews.loc[0, 'reviews.doRecommend'] # first recommendation\n",
    "print(vtxt)\n",
    "recom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1e252886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'found fire tv great buy love take everywher note prime tv not work countri oversea netflix still find lot thing watch road rent movi amazon paid no prime unfortun us no problem highli recommend'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing to review text\n",
    "reviews['preprocessed_text'] = reviews['reviews.text'].apply(preprocess_text)\n",
    "reviews['preprocessed_text'].loc[len(reviews)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "78e54bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Feature Engineering**\n",
    "# Extract TF-IDF features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(reviews['preprocessed_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddccb18",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5eb5398b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, reviews['reviews.doRecommend'], test_size=0.2)\n",
    "y_train.unique() # must have both [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "958ab911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')\n",
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f1acefc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a logistic regression classifier\n",
    "model = LogisticRegression(solver=\"liblinear\") #solver={'lbfgs', \"liblinear\", \"sag\", \"saga\"}\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c4eb0999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9619900205459349\n"
     ]
    }
   ],
   "source": [
    "# **Model Evaluation**\n",
    "# Predict sentiment on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b966aa52",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fcbd1508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not like item not recommend'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing to review text\n",
    "txt = \"I do not like this item and I do not recommend it!\"\n",
    "txt_preproc = preprocess_text(txt)\n",
    "txt_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "65ed7218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x13448 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_vect = vectorizer.transform([txt_preproc])\n",
    "txt_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3bff2cb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(txt_vect) # 1 - recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "686a6202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any predictions of 0\n",
    "(model.predict(X_test)==0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60dc729",
   "metadata": {},
   "source": [
    "## Second Variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e54cd1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c0a4132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "43741fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9614029938362195\n"
     ]
    }
   ],
   "source": [
    "# Preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and numbers\n",
    "    text = ''.join([char for char in text if not char.isdigit() and not char in string.punctuation])\n",
    "    # Tokenize words\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    for w in ['no','not']: stopwords.remove(w) # remove 'no' and 'not' from the list of stop words\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "    # Lemmatize words\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply text preprocessing to review column\n",
    "df['preprocessed_text'] = df['reviews.text'].apply(preprocess_text)\n",
    "\n",
    "# Extract relevant features using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['preprocessed_text'])\n",
    "\n",
    "# Split data into train and test sets\n",
    "y = df['reviews.doRecommend']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train a machine learning classifier\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model performance\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7bbbabe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not like item not recommend'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing to review text\n",
    "txt = \"I do not like this item and I do not recommend it!\"\n",
    "txt_preproc = preprocess_text(txt)\n",
    "txt_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "009fee62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x15537 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_vect = vectorizer.transform([txt_preproc])\n",
    "txt_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "85307374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(txt_vect) # 1 - recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177275d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
